---
layout: page
title: "Week Seven: Video"
hide_warning: true
---

## Tutorial: Video

Generative AI video is still emerging, but it's already made an impact on the industry: among other adopters, a recent Netflix science fiction  while there are many tools available already using the capabilities of the technology to assist in the modification of video content, relatively few models have been released that allow for full image-to-video or text-to-video content directly to the consumer market. Precursors to these tools, such as deepfakes video creators for working from photos or video to create false content featuring particular people, generally require dataset preparation of a type we won't be engaging here. Instead, we'll be running a limited experiment with generative video this week, then looking at the larger claims and outputs from companies developing tools in this space.

### Image to Video Exploration

For this exercise, try either working from static images or from specific descriptions. For instance, this example was created using Google Gemini Veo 3 with the prompt: "a retrofuturist alien spaceship lands on memory mall at the University of Central Florida:" 

<video src="Veo3.mp4"></video>

Compare this to a second iteration of the same prompt (using the same model on the same day), but with additional information from this [Wikimedia photo](https://commons.wikimedia.org/wiki/File:UCF_Memory_Mall_(30395273585).jpg) of the UCF memory mall:

<video src="VeoWithReference.mp4"></video>

Here's the Sora output from the exact same prompt and source image:

<video src="Sora.mp4"></video>

Try both ways of working after selecting either a tool that you have access to through an existing account (usually with Google or OpenAI) or from this [comprehensive list of video tools](https://www.whytryai.com/p/free-ai-image-to-video-tools-tested) that includes samples of output and free options, and the [Tom's Guide to generative video](https://www.tomsguide.com/features/5-best-ai-video-generators-tested-and-compared). Generate 2-3 short videos to share with your peers, using either one tool, or a range. 

### Critiquing Generated Video

Now that you've explored the tools within some limitations, choose a generated video to analyze and critique, with particular attention to the tensions of perception, vision, and labor drawn out through this week's readings. Keep in mind the concerns raised in Brett Halperin's talk, ["Hollywood Film Workers Strike Against AI: Understanding Algorithmic Resistance to Generative Cinematography"](https://stars.library.ucf.edu/elo2024/algorithmsandimaginaries/schedule/3/), as well as the current news coverage around greater integration of AI into cinematic productions such as the recent [usage by Netflix](https://www.theguardian.com/media/2025/jul/18/netflix-uses-generative-ai-in-show-for-first-time-el-eternauta). If you have access to a Netflix subscription, I recommend watching the episode in question.

Also explore coverage of commercial and artistic deployments of AI video:
- [Microsoft Surface AI ads](https://www.theverge.com/news/656104/microsoft-surface-ad-generative-ai-copilot-intel)
- [ILM Star Wars Field Guide](https://decrypt.co/320224/ilm-makes-star-wars-field-guide-short-film-using-generative-ai)
- [AI generated music videos](https://sfstandard.com/2024/09/27/ai-generated-music-videos-hackathon/)
- [Yelp creating AI videos about restaurants](https://www.theverge.com/news/714944/yelp-ai-stitched-videos)

Contextualize the generation you've done in these larger debates: what does the video you've generated suggest about the future of misinformation? Environmental and disaster communication? Conspiracy theories? How are people in your field using, or refusing to use, these tools? If this is your first time using them, were you surprised by the results?

### Discussion

Your discussion post should combine your knowledge (and samples) from your own exploration of generative video with your observations about the form drawing on the example you've selected for analysis. Make sure to include the link to the video you've selected as well as relevant context, so that we can all build a better sense of the state of the field from the range of works critiqued.
